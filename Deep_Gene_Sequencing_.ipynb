{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Gene Sequencing .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO248xY4KGyzEwtllmMRHxD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DockingBlade/Gene-Sequencing-/blob/main/Deep_Gene_Sequencing_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IJ6IVLKpajz"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import sklearn\r\n",
        "from sklearn import preprocessing as sklpp\r\n",
        "from sklearn import decomposition as skldecomp \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.neighbors import KNeighborsRegressor\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\r\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\r\n",
        "import torch\r\n",
        "from numpy import array, newaxis, expand_dims"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xnktQqppg8O"
      },
      "source": [
        "df = pd.read_csv('splice.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sPZM02xpjAe",
        "outputId": "f564c7e0-a13c-47af-f473-63594ce13302"
      },
      "source": [
        "numDataSamples = df.shape[0];\r\n",
        "numAttributes = df.shape[1];\r\n",
        "\r\n",
        "print('The number of Data Samples is ', numDataSamples);\r\n",
        "print('The number of Attributes is ', numAttributes, ' but the Donor variable is not relevant to classification, since it is an identifier for the sample and does not have information relevant to the sample so there are really ', numAttributes-1);\r\n",
        "print( 'attributes with 1 attribute as the Label or Dependent variable and ', numAttributes-2, ' independent variables, in this case nucleotides');\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Checing that all the nucleotide values are valid"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of Data Samples is  3190\n",
            "The number of Attributes is  62  but the Donor variable is not relevant to classification, since it is an identifier for the sample and does not have information relevant to the sample so there are really  61\n",
            "attributes with 1 attribute as the Label or Dependent variable and  60  independent variables, in this case nucleotides\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlsstqjEplkI",
        "outputId": "a36f0889-a49c-4b80-aeef-f2067b57625f"
      },
      "source": [
        "#Pre-Processing\r\n",
        "\r\n",
        "#Checing that all the nucleotide values are valid\r\n",
        "for col in range(1,61):\r\n",
        "    index = str(col);\r\n",
        "    df.loc[((df[index] != 'A') & (df[index] != 'C') & (df[index] != 'G') & (df[index] != 'T')), index]= pd.NA\r\n",
        "\r\n",
        "if df.isnull().values.any():\r\n",
        "    print('Dataframe contains invalid values in the nucleotide sequences')\r\n",
        "else:\r\n",
        "    print('All entries in the nucleotide sequences are valid.')\r\n",
        "\r\n",
        "df = df.dropna();\r\n",
        "\r\n",
        "print('So in the dataset set description it mentions that nucleotides with abigious values were given different character values than A,G,C, and T. Thus I decided to remove these rows from the dataset, and now there are ',df.shape[0] , ' samples remaining');\r\n",
        "\r\n",
        "index = 'Label';\r\n",
        "df.loc[((df[index] != 'IE') & (df[index] != 'EI') & (df[index] != 'N') ), index]= pd.NA\r\n",
        "\r\n",
        "if df.isnull().values.any():\r\n",
        "    print('Dataframe contains invalid values in the Labels')\r\n",
        "else:\r\n",
        "    print('All entries in the Labels are now valid.')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Label encoding the nucleotides\r\n",
        "for col in range(1,61):\r\n",
        "    index = str(col);\r\n",
        "    df[index] = df[index].replace(['A','C','G','T'],[0, 1, 2, 3]);\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "df['Label'] = df['Label'].replace(['IE','EI','N'],[0, 1, 2]);"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataframe contains invalid values in the nucleotide sequences\n",
            "So in the dataset set description it mentions that nucleotides with abigious values were given different character values than A,G,C, and T. Thus I decided to remove these rows from the dataset, and now there are  3175  samples remaining\n",
            "All entries in the Labels are now valid.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ8uSpcfppnH",
        "outputId": "391066b2-872d-4136-cb4d-487104a8bca0"
      },
      "source": [
        "#Feature Learning - PCA\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "nucleotides = df.iloc[:,np.r_[2:62]].to_numpy();\r\n",
        "labels = df.iloc[:,np.r_[0]].to_numpy();\r\n",
        "\r\n",
        "mean_datascaler = sklpp.StandardScaler(with_mean=True, with_std=False);\r\n",
        "data_pca = skldecomp.PCA(n_components=0.95, svd_solver='full');\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(nucleotides, labels, test_size=0.20, shuffle=True);\r\n",
        "\r\n",
        "X_train = mean_datascaler.fit_transform(X_train);\r\n",
        "X_train =  data_pca.fit_transform(X_train);\r\n",
        "mean = np.array(mean_datascaler.mean_);\r\n",
        "\r\n",
        "test_X = X_test.astype(np.float64, copy=False)\r\n",
        "for i in range(np.shape(test_X)[0]):\r\n",
        "  test_X[i,:] -= mean;\r\n",
        "\r\n",
        "U = np.transpose(data_pca.components_);\r\n",
        "U_transpose = np.transpose(U);\r\n",
        "Xtest_transpose = U_transpose @ np.transpose(test_X);\r\n",
        "X_test = np.transpose(Xtest_transpose);\r\n",
        "\r\n",
        "print('Shape of X_train,\\n', X_train.shape);\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train,\n",
            " (2540, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4nuFWVFouoo"
      },
      "source": [
        "class Net(torch.nn.Module):\r\n",
        "  def __init__(self, n_features):\r\n",
        "    super(Net,self).__init__();\r\n",
        "    self.lin_1 = torch.nn.Conv1d(56,64,1,2);\r\n",
        "    self.lin_2 = torch.nn.Conv1d(64,128,1,2);\r\n",
        "    self.lin_3 = torch.nn.Conv1d(128,256,1,2);\r\n",
        "    self.lin_4 = torch.nn.Conv1d(256,512,1,2);\r\n",
        "    self.lin_5 = torch.nn.Conv1d(512,1024,1,2);\r\n",
        "    \r\n",
        "    self.lin_6 = torch.nn.Linear(1024,512);\r\n",
        "    self.lin_7 = torch.nn.Linear(512,256);\r\n",
        "    self.lin_8 = torch.nn.Linear(256,128);\r\n",
        "    self.lin_9 = torch.nn.Linear(128,64);\r\n",
        "    self.lin_10 = torch.nn.Linear(64,3);\r\n",
        "\r\n",
        "    self.dropout = torch.nn.Dropout(0.2)\r\n",
        "\r\n",
        "  def forward(self,x) :\r\n",
        "    x = torch.nn.functional.tanh( self.lin_1(x));\r\n",
        "    x = torch.nn.functional.tanh( self.lin_2(x));\r\n",
        "    x = torch.nn.functional.tanh( self.lin_3(x));\r\n",
        "    x = torch.nn.functional.tanh( self.lin_4(x));\r\n",
        "    x = torch.nn.functional.tanh( self.lin_5(x));\r\n",
        "    \r\n",
        "    x= x.view(x.size()[0], -1)\r\n",
        "    \r\n",
        "    x = torch.nn.functional.tanh( self.dropout(self.lin_6(x)));\r\n",
        "    x = torch.nn.functional.tanh( self.dropout(self.lin_7(x)));\r\n",
        "    x = torch.nn.functional.tanh( self.dropout(self.lin_8(x)));\r\n",
        "    x = torch.nn.functional.tanh( self.dropout(self.lin_9(x)));\r\n",
        "    x = torch.nn.functional.tanh(self.dropout(self.lin_10(x)));\r\n",
        "    return x; "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFEVDc9NpApp",
        "outputId": "e90b5c8b-2678-49ab-b093-d5fff20c1c5f"
      },
      "source": [
        "X_train = torch.from_numpy(X_train);\r\n",
        "X_test = torch.from_numpy(X_test);\r\n",
        "y_train = torch.from_numpy(np.transpose(y_train));\r\n",
        "y_test = torch.from_numpy(np.transpose(y_test));\r\n",
        "print(y_train);\r\n",
        "print(y_test);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2, 1, 0,  ..., 2, 2, 2]])\n",
            "tensor([[2, 2, 2, 2, 1, 0, 0, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 1, 0,\n",
            "         2, 2, 1, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 0,\n",
            "         2, 0, 2, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0, 1, 2, 0, 2, 0, 2, 2,\n",
            "         2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 0, 2, 1, 1, 2, 1, 1, 0, 2, 2, 0, 2, 2,\n",
            "         0, 0, 0, 0, 2, 2, 1, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2,\n",
            "         2, 2, 1, 2, 0, 2, 0, 2, 0, 1, 2, 0, 1, 2, 2, 2, 0, 2, 1, 0, 0, 2, 0, 1,\n",
            "         0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 1, 2, 2, 2, 1, 2, 1, 1, 2,\n",
            "         0, 1, 0, 0, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 1, 0, 2, 0, 2, 1, 1,\n",
            "         1, 2, 0, 2, 2, 0, 2, 1, 2, 2, 1, 1, 0, 2, 0, 0, 0, 2, 1, 1, 2, 2, 0, 2,\n",
            "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 0, 2, 1, 2, 0, 2, 0, 1,\n",
            "         1, 2, 2, 2, 2, 2, 0, 0, 2, 1, 0, 1, 0, 1, 0, 1, 2, 2, 0, 1, 1, 1, 2, 2,\n",
            "         2, 1, 2, 2, 1, 0, 2, 1, 2, 2, 1, 0, 0, 0, 2, 2, 1, 2, 1, 0, 2, 0, 1, 1,\n",
            "         2, 0, 1, 0, 1, 0, 2, 2, 2, 2, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 1, 0, 1, 2,\n",
            "         2, 1, 0, 2, 2, 2, 1, 2, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 2, 1, 0, 1, 2,\n",
            "         0, 2, 0, 1, 2, 0, 0, 2, 1, 2, 2, 0, 2, 2, 2, 0, 2, 1, 1, 2, 2, 1, 2, 2,\n",
            "         2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 1, 2, 1, 0, 2, 2, 2, 2, 1,\n",
            "         0, 1, 2, 2, 1, 1, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2,\n",
            "         2, 0, 2, 1, 0, 1, 1, 0, 2, 1, 2, 2, 2, 2, 2, 0, 1, 2, 1, 1, 2, 2, 2, 1,\n",
            "         2, 0, 2, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 1, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0,\n",
            "         2, 0, 2, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 0, 2, 2, 1, 2, 0, 2, 0, 1, 0, 2,\n",
            "         2, 2, 2, 2, 0, 2, 2, 1, 1, 2, 1, 2, 2, 0, 2, 2, 1, 0, 0, 0, 2, 1, 2, 2,\n",
            "         1, 0, 2, 1, 1, 2, 2, 0, 0, 2, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 0, 2, 0, 2,\n",
            "         0, 2, 1, 1, 2, 2, 1, 0, 2, 2, 2, 2, 0, 2, 2, 2, 1, 1, 1, 2, 2, 0, 0, 2,\n",
            "         1, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 0, 2, 0, 2, 1, 0,\n",
            "         1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 1, 0, 0, 2,\n",
            "         1, 1, 0, 1, 1, 0, 2, 2, 2, 2, 2, 2, 1, 1, 0, 1, 1, 2, 1, 1, 1, 2, 0, 2,\n",
            "         2, 2, 0, 0, 0, 2, 0, 2, 2, 2, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nANNc1AtpEdl"
      },
      "source": [
        "y_train = y_train.flatten();\r\n",
        "y_test = y_test.flatten();\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX4twVkDpI0b"
      },
      "source": [
        "net = Net(X_train.shape[1]);\r\n",
        "loss = torch.nn.CrossEntropyLoss();\r\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr = 0.001);\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzCRSOA-pMrJ"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\r\n",
        "X_train.to(device);\r\n",
        "X_test.to(device);\r\n",
        "y_train.to(device);\r\n",
        "y_test.to(device);"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcE4S4aWpQI8",
        "outputId": "3e530535-a746-4b0d-95ab-5a9711d9e0e1"
      },
      "source": [
        "net.double();\r\n",
        "net.train()\r\n",
        "for epoch in range(60):\r\n",
        "  print(epoch);\r\n",
        "  #pred = torch.max(net(X_train),1);\r\n",
        "  pred = net(torch.from_numpy(np.array(X_train)[:, :, newaxis]));\r\n",
        "  train_loss = loss(pred,y_train);\r\n",
        "  optimizer.zero_grad()\r\n",
        "  train_loss.backward()\r\n",
        "  optimizer.step()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cgqUBYopUqZ",
        "outputId": "4fe3e558-a1ad-4b8d-80e0-eea516d9d855"
      },
      "source": [
        "net.eval();\r\n",
        "pred = torch.max(net(torch.from_numpy(np.array(X_test)[:, :, newaxis])),1)[1];\r\n",
        "\r\n",
        "Recall = recall_score(y_test,pred,average= 'micro');\r\n",
        "Precision = precision_score(y_test,pred,average='micro');\r\n",
        "F_score = (2 * Recall * Precision)/(Recall + Precision);\r\n",
        "print('The accuracy for deep learning is ' , accuracy_score(y_test,pred));\r\n",
        "print('The confusion matrix for deep learning is \\n', confusion_matrix(y_test,pred, normalize='true'))\r\n",
        "print('The precision for deep learning is ',precision_score(y_test,pred, average='micro'));\r\n",
        "print('The recall for deep learning is ', recall_score(y_test,pred, average='micro') );\r\n",
        "print('The F score for deep learning is ', F_score);\r\n",
        "# for layer in net.children():\r\n",
        "#   if hasattr(layer, 'reset_parameters'):\r\n",
        "#     layer.reset_parameters()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The accuracy for deep learning is  0.8346456692913385\n",
            "The confusion matrix for deep learning is \n",
            " [[0.82352941 0.06535948 0.11111111]\n",
            " [0.06451613 0.86451613 0.07096774]\n",
            " [0.11009174 0.06422018 0.82568807]]\n",
            "The precision for deep learning is  0.8346456692913385\n",
            "The recall for deep learning is  0.8346456692913385\n",
            "The F score for deep learning is  0.8346456692913384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS3aaW6AC_Kl"
      },
      "source": [
        "Deep learning ended up performing just as well as the other methods, but no better. I tried to expand the size of the network but this caused the network to label all the Gene Sequences as Neither (the largest class). Furthermore, I had the same issue before I changed the activation function from ReLu to tanh. My theory is that since all the outputs have all positive and 0 elements, and the inputs have all positive and 0 elements, the network was learning mostly positive values for all the parameters, and thus ReLu was minimally in creating non-linearities. "
      ]
    }
  ]
}